{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prakhar Jain\n",
    "# 2022121008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "from preprocess import TextProcessor, Vocabulary, TextDataset, TextDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implement the Language Model and report the Perplexity Scores. [40 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Auguste_Maquet.txt\"\n",
    "glove_path = \"glove.6B.300d.txt\"\n",
    "# can use fasttext as well just by specifying the path\n",
    "\n",
    "text_processor = TextProcessor(file_path)\n",
    "sentences = text_processor.preprocess_text()\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(sentences)\n",
    "\n",
    "val_len = 10000\n",
    "test_len = 20000\n",
    "\n",
    "train_sentences = sentences[val_len + test_len:]\n",
    "val_sentences = sentences[:val_len]\n",
    "test_sentences = sentences[val_len:val_len + test_len]\n",
    "\n",
    "train_ngrams = text_processor.generate_ngrams(train_sentences, 5 + 1) # 5 for context and 1 for target\n",
    "val_ngrams = text_processor.generate_ngrams(val_sentences, 5 +1)\n",
    "test_ngrams = text_processor.generate_ngrams(test_sentences, 5 + 1)\n",
    "\n",
    "vocabulary = Vocabulary(glove_path)\n",
    "vocabulary.build_vocab(train_sentences)\n",
    "embeddings = vocabulary.get_glove_embeddings()\n",
    "\n",
    "train_dataset = TextDataset(train_ngrams, vocabulary)\n",
    "val_dataset = TextDataset(val_ngrams, vocabulary)\n",
    "test_dataset = TextDataset(test_ngrams, vocabulary)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 28487\n",
      "Val: 10000\n",
      "Test: 20000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {len(train_sentences)}\")\n",
    "print(f\"Val: {len(val_sentences)}\")\n",
    "print(f\"Test: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S> the wounds that i make\n",
      "<S>\n",
      "1 1\n",
      "the\n",
      "3 3\n",
      "wounds\n",
      "4 4\n",
      "that\n",
      "5 5\n",
      "i\n",
      "6 6\n",
      "make\n",
      "7 7\n"
     ]
    }
   ],
   "source": [
    "## test functionality\n",
    "print(train_ngrams[0])\n",
    "\n",
    "for batch in train_loader:\n",
    "    for x in batch[0][0]:\n",
    "        print(vocabulary.index2word(x.item()))\n",
    "        print(str(x.item()) +\" \"+str(vocabulary.word2index(vocabulary.index2word(x.item()))))\n",
    "\n",
    "    # print the target word\n",
    "    print(vocabulary.index2word(batch[1][0].item()))\n",
    "    print(str(batch[1][0].item()) +\" \"+str(vocabulary.word2index(vocabulary.index2word(batch[1][0].item()))))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16377, 300])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding, dropout):\n",
    "        super(NeuralLanguageModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(5 * embedding_dim, 300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(300, vocab_size)\n",
    "            # nn.LogSoftmax(dim=1) # CrossEntropyLoss already applies log softmax\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is a tensor of shape (batch_size, 5)    \n",
    "        embeds = self.embedding(x)\n",
    "        embeds = embeds.view(-1, 5 * self.embedding_dim) # flatten the tensor\n",
    "        output = self.model(embeds)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "\n",
    "Check out reduction parameter in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralLanguageModel(vocab_size=embeddings.shape[0], embedding_dim=embeddings.shape[1], hidden_dim=300, embedding=embeddings, dropout=0.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0fd0b53348411285a9929b9dd03235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6944563ce14fa0b116d5238750e417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Train Loss: 5.9217 Train Perplexity: 373.0388 Val Loss: 5.6788 Val Perplexity: 292.5891\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f44605ef1b84ea29752d9cf30ab12c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06ee3683fe94938ba71007e646006d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 Train Loss: 5.7456 Train Perplexity: 312.8245 Val Loss: 5.7593 Val Perplexity: 317.1230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3557674a948b4907b62c0d4c60f11c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1008d3ca2fd1472e8ff96efca6cd14e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Train Loss: 5.6972 Train Perplexity: 298.0199 Val Loss: 5.9203 Val Perplexity: 372.5162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d061252b602a4f6e99a783b0d8c8fc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4351d0c50c324e9689bf80f2c771187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 Train Loss: 5.6723 Train Perplexity: 290.7104 Val Loss: 6.0288 Val Perplexity: 415.2341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1924bdbbb1604f99ad23628078f8bc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f9d6aa8c9c4e2ab647763b007edc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 Train Loss: 5.6558 Train Perplexity: 285.9366 Val Loss: 6.0642 Val Perplexity: 430.1995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cca28d0c6446de81311e831bd04c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043c1b952121429cb89cb7984f67eae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 Train Loss: 5.6512 Train Perplexity: 284.6268 Val Loss: 6.1288 Val Perplexity: 458.8689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26622766da14f628015b2ab13b33bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0fc86d0d534686b2d10c2150ee9be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 Train Loss: 5.6660 Train Perplexity: 288.8898 Val Loss: 6.1808 Val Perplexity: 483.3833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e67df73c36c44afaaecf385ebef803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad1cd22a4b74997845adcebe72f56bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 Train Loss: 5.6718 Train Perplexity: 290.5657 Val Loss: 6.2062 Val Perplexity: 495.8129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3bdb1d077542ce9eeef787085270c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c7e2e5cd9e46c89178e96b62895ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 Train Loss: 5.6911 Train Perplexity: 296.2233 Val Loss: 6.2679 Val Perplexity: 527.3727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfc4b4e992f46f3a2714d99d4186022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7109 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6098e473eb4096a47bbbcd23c3e924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 Train Loss: 5.6976 Train Perplexity: 298.1384 Val Loss: 6.3279 Val Perplexity: 560.0063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52735aaf4e744e7b54bccd67c1ea4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4979 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 6.4457 Test Perplexity: 629.9795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_perplexity(loss):\n",
    "    # perplexity = exp(cross_entropy) this is a direct relationship between cross entropy and perplexity\n",
    "    return torch.exp(torch.tensor(loss))\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        context, target = batch\n",
    "        context, target = context.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(context)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    # avg_loss = total_loss / len(train_loader)\n",
    "    perplexity = calculate_perplexity(avg_loss)\n",
    "    return avg_loss, perplexity\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(val_loader):\n",
    "            context, target = batch\n",
    "            context, target = context.to(device), target.to(device)\n",
    "            output = model(context)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "    # avg_loss = total_loss / len(val_loader)\n",
    "    perplexity = calculate_perplexity(avg_loss)\n",
    "    return avg_loss, perplexity\n",
    "\n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_loader):\n",
    "            context, target = batch\n",
    "            context, target = context.to(device), target.to(device)\n",
    "            output = model(context)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    # avg_loss = total_loss / len(test_loader)\n",
    "    perplexity = calculate_perplexity(avg_loss)\n",
    "    return avg_loss, perplexity\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_perplexity = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_perplexity = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs} Train Loss: {train_loss:.4f} Train Perplexity: {train_perplexity:.4f} Val Loss: {val_loss:.4f} Val Perplexity: {val_perplexity:.4f}\")\n",
    "\n",
    "\n",
    "test_loss, test_perplexity = test(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f} Test Perplexity: {test_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Bonus** Plot graphs showing the variation of average train/test perplexities with varying hyperparameters  like Dropout rate, changing the dimensions of the layers, changing the Optimizer, etc. Report the most optimal Hyperparameters found. [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (686894790.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    'hidden_dim': ,\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "HYPERPARAMS = {\n",
    "    'hidden_dim': ,\n",
    "    'optimizer': ,\n",
    "    'dropout': ,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
